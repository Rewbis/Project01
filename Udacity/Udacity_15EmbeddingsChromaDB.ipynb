{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a081db99-2260-4abb-9eea-8191f183b1b7",
   "metadata": {},
   "source": [
    "## Summary: Understanding Embeddings in LangGraph Workflows  \n",
    "Overview  \n",
    "This demo develops intuition about embeddings—dense vector representations of text—and how to use them for similarity search and visualization. It introduces building embeddings with Hugging Face or OpenAI, comparing semantic similarity, and visualizing embeddings in 2D space.\n",
    "  \n",
    "Key Steps Covered  \n",
    "1. Embeddings Factory Setup  \n",
    "A simple EmbeddingsFactory class is built to support two providers:\n",
    "\n",
    "Hugging Face models (e.g., all-MiniLM-L6-v2)\n",
    "\n",
    "OpenAI Embeddings (via API key)\n",
    "\n",
    "\n",
    "class EmbeddingsFactory:\n",
    "\n",
    "  def __init__(self, provider):\n",
    "\n",
    "      ...\n",
    "Hugging Face models are freely available and downloaded automatically.\n",
    "\n",
    "OpenAI models require an API key and internet access."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df353d28-d32e-4d05-a109-c6c6fd51110a",
   "metadata": {},
   "source": [
    "L4_demo_03_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef61491-a24f-4c95-a012-fa168f7291ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal, List, Dict\n",
    "import itertools\n",
    "from langchain_core.embeddings import Embeddings\n",
    "from langchain_openai.embeddings import OpenAIEmbeddings\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "import numpy as np\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87741b36-4d1d-4bbc-8db3-32b6c6d4f5a7",
   "metadata": {},
   "source": [
    "Embeddings intuition  \n",
    "2. Sentence List Creation  \n",
    "Six sample sentences are prepared: Grouped into three pairs of similar sentences.\n",
    "Example:  \n",
    "\"The cat sat on the mat.\" and \"A cat was resting on a mat.\"\n",
    "sentences = [\n",
    "  \"The cat sat on the mat.\",\n",
    "  \"A cat was resting on a mat.\",\n",
    "  \"The sun is bright today.\",\n",
    "  \"It’s sunny and warm outside.\",\n",
    "  \"I love reading books at night.\",\n",
    "  \"Reading at bedtime is my favorite.\"\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4479f74c-a9fa-4751-925e-28edd82a0b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmbeddingsFactory:\n",
    "    def __init__(self, \n",
    "                 provider:Literal[\"OpenAI\", \"HugginFace\"],\n",
    "                 **kwargs):\n",
    "        self.provider = provider\n",
    "        self.kwargs = kwargs\n",
    "    \n",
    "    def create(self) -> Embeddings:\n",
    "        if self.provider == \"OpenAI\":\n",
    "            return OpenAIEmbeddings(**self.kwargs)\n",
    "        if self.provider == \"HugginFace\":\n",
    "            return HuggingFaceEmbeddings(**self.kwargs)\n",
    "        raise ValueError(f\"Unknown embeddings provider: {self.provider}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40ac8d8c-2ba3-4164-aa67-4d99214a0b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_list = [\n",
    "    \"I want to listen to music again\",\n",
    "    \"I'm in the mood to hear music once more.\",\n",
    "    \"Playstation has been a big part of my childhood\",\n",
    "    \"I grew up playing Nintendo games\",\n",
    "    \"The place I visited is the same as before\",\n",
    "    \"The destination I returned to hasn’t changed over the years\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d613db8-54f1-4351-8bd0-c140b6632b84",
   "metadata": {},
   "source": [
    "3. Generating Embeddings  \n",
    "Hugging Face embeddings are generated for each sentence.\n",
    "\n",
    "Each embedding is a 384-dimensional vector.\n",
    "\n",
    "\n",
    "embeddings = [embeds.embed_query(sentence) for sentence in sentences]\n",
    "These vectors encode semantic meaning: similar sentences yield similar vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33333ca3-dd5d-460d-8db5-42f8e67e04e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HuggingFace\n",
    "# https://huggingface.co/sentence-transformers/all-MiniLM-L6-v2\n",
    "# try moving this over to openAI\n",
    "embeddings = EmbeddingsFactory(\n",
    "    provider=\"HugginFace\",\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    encode_kwargs={'normalize_embeddings': False}\n",
    ").create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31400c44-89b4-46ae-a5d1-799cc7936461",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "embeddings = EmbeddingsFactory(\n",
    "    provider=\"OpenAI\"\n",
    ").create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5846da9a-59b5-453f-b954-a26bdaa5c347",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_list = [\n",
    "    embeddings.embed_query(sentence)\n",
    "    for sentence in sentence_list\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fd8388b-5004-491f-8267-af67c8252eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embeddings_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd15ca1f-1554-4cde-8d3b-65d9a159dd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embeddings_list[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0a620ef-4df9-473f-8477-c52971010e06",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_list[0][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bc28c19-7371-483a-b37a-c5538c624925",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeddings_map = [\n",
    "    {\"sentence\":sentence, \"embeddings\":embeddings}\n",
    "    for sentence,embeddings in zip(sentence_list, embeddings_list)\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb05c5e4-9a19-4df3-8173-ce16178208de",
   "metadata": {},
   "source": [
    "4. Computing Similarities  \n",
    "Using dot product from NumPy, semantic similarity between embeddings is calculated.\n",
    "\n",
    "Pairs of similar sentences have higher similarity scores (e.g., 0.62, 0.58, 0.56).\n",
    "\n",
    "Non-related sentences yield lower similarity scores.\n",
    "  \n",
    "\n",
    "similarity_score = np.dot(embedding1, embedding2)\n",
    "Results demonstrate that embeddings capture semantic (not just lexical) similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbdf4da-0f29-4d99-8232-6646a3dc692d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_similarity(\n",
    "        sentence_embeddings_map:List[Dict], \n",
    "        i1:int=0, \n",
    "        i2:int=1)->None:\n",
    "    s1 = sentence_embeddings_map[i1][\"sentence\"]\n",
    "    e1 = sentence_embeddings_map[i1][\"embeddings\"]\n",
    "    s2 = sentence_embeddings_map[i2][\"sentence\"]\n",
    "    e2 = sentence_embeddings_map[i2][\"embeddings\"]\n",
    "    print(f\"Score: {np.dot(e1,e2):.2f}\\n\")\n",
    "    print(f\"Sentence {i1}: {s1}\\nSentence {i2}: {s2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a23d08-f807-490a-b5ef-54b047ddb65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_similarity(sentence_embeddings_map,0,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2de470-8c51-48af-8286-a14b603bb424",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_similarity(sentence_embeddings_map,2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d25c64fd-aaf6-4d31-b4f3-5f97f7df56eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_similarity(sentence_embeddings_map,4,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47e72319-32c7-42ff-a373-07c9b4878ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_similarity(sentence_embeddings_map,0,3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22623b41-7aa0-4908-964f-69146b021215",
   "metadata": {},
   "source": [
    "5. Dimensionality Reduction  \n",
    "Embeddings (384 dimensions) are too large to visualize easily.\n",
    "\n",
    "Dimensionality reduction is performed (e.g., via PCA) to map embeddings into 2D space.\n",
    "\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "\n",
    "embeddings_2d = pca.fit_transform(embeddings)\n",
    "Although some information is lost, this allows easier visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2a580b-da4d-4473-ba5c-ba36591789f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca_model = PCA(n_components=2)\n",
    "pca_model.fit(embeddings_list)\n",
    "new_values = pca_model.transform(embeddings_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a748ce4-f5a9-464b-90eb-ebf2456a9180",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"shape: {new_values.shape}\")\n",
    "print(new_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea2002e-4346-4949-9d75-e5f6f14cbbcb",
   "metadata": {},
   "source": [
    "6. Visualization  \n",
    "A scatterplot is created showing embeddings in 2D space.\n",
    "\n",
    "Sentences with similar meaning are plotted close together.\n",
    "  \n",
    "\n",
    "plt.scatter(...)\n",
    "\n",
    "for i, sentence in enumerate(sentences):\n",
    "\n",
    "  plt.annotate(sentence, ...)\n",
    "Visualization confirms:\n",
    "\n",
    "Similar sentences cluster together.\n",
    "\n",
    "Dissimilar sentences are further apart."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2d11c0-447f-44e8-9b15-bd72543eeee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_2d(x_values, y_values, info_list):\n",
    "    fig, ax = plt.subplots()\n",
    "    scatter = ax.scatter(\n",
    "        x_values,\n",
    "        y_values,\n",
    "        alpha=0.5,\n",
    "        edgecolors='k',\n",
    "        s=40\n",
    "    )\n",
    "\n",
    "    ax.set_title(\"Embeddings Viz in 2D\")\n",
    "    ax.set_xlabel(\"X_1\")\n",
    "    ax.set_ylabel(\"X_2\")\n",
    "\n",
    "    for i, info in enumerate(info_list):\n",
    "        ax.annotate(info, (x_values[i], y_values[i]))\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e6cecf-f1d6-428a-b55d-7369d5dc4209",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d(new_values[:,0], new_values[:,1], sentence_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "652e6cc5-390a-4b62-96c5-509d8edc375b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9978e909-623f-4816-be31-44b17f9949db",
   "metadata": {},
   "source": [
    "7. Switching Providers  \n",
    "Switching from Hugging Face to OpenAI:\n",
    "\n",
    "OpenAI embeddings are larger (e.g., 1536 dimensions).\n",
    "\n",
    "Higher-dimensional embeddings may better capture subtle semantic differences.\n",
    "\n",
    "Procedure is the same; only provider changes.\n",
    "\n",
    "\n",
    "embeds = EmbeddingsFactory(provider=\"openai\")  \n",
    "8. Key Concepts Highlighted  \n",
    "Embeddings represent the meaning of text numerically.\n",
    "\n",
    "Similarity between embeddings reflects semantic closeness.\n",
    "\n",
    "Dimensionality reduction sacrifices precision but increases explainability.\n",
    "\n",
    "Provider choice affects embedding quality, size, and performance.\n",
    "  \n",
    "9. Conclusion  \n",
    "Embeddings are the backbone of RAG, retrieval, recommendation systems, and clustering tasks.\n",
    "\n",
    "Understanding how to create, compare, and visualize embeddings is fundamental to building AI systems that understand natural language at a deeper level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2adaf051-72be-4b6b-9edb-203a7f7d1224",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6b56349-4dc5-4b94-8fca-363d210b573c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a440f239-3d6b-4a29-8445-44c2918b966d",
   "metadata": {},
   "source": [
    "## Next demo: Using ChromaDB\n",
    "Summary: Using ChromaDB for Embedding Storage and Retrieval\n",
    "Overview\n",
    "This demo shows how to apply embeddings in practice using ChromaDB, a vector database. It walks through inserting documents, querying with semantic similarity, switching embedding models, and eventually integrating ChromaDB with LangChain."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "620da5af-c806-46f2-88c2-7d0531ead661",
   "metadata": {},
   "source": [
    "Key Steps Covered  \n",
    "1. Initial Setup  \n",
    "Five sentences (mini news articles) are created.\n",
    "\n",
    "Topics include Meta, Nvidia, Google, Intel, and more.\n",
    "\n",
    "\n",
    "sentences = [\n",
    "  \n",
    "  \"Meta drops multimodal Llama model.\",\n",
    "\n",
    "  \"Chip giant Nvidia acquires OctoAI.\",\n",
    "\n",
    "  \"Google brings Gemini to older Pixel Buds.\",\n",
    "\n",
    "  \"Intel Battlemage GPU benchmarks leaked.\",\n",
    "\n",
    "  \"Nvidia CEO reveals new AI chip roadmap.\"\n",
    "  \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff663fb1-9592-4893-ad3a-2d137698d770",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import chromadb\n",
    "from chromadb.utils import embedding_functions\n",
    "from langchain_chroma import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings\n",
    "from langchain_core.documents import Document\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae25296-efae-45cb-8a5b-d0e766cc9420",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_list = [\n",
    "    \"Meta drops multimodal Llama 3.2 — here's why it's such a big deal\",\n",
    "    \"Chip giant Nvidia acquires OctoAI, a Seattle startup that helps companies run AI models\",\n",
    "    \"Google is bringing Gemini to all older Pixel Buds\",\n",
    "    \"The first Intel Battlmage GPU benchmarks have leaked\",\n",
    "    \"Dell partners with Nvidia to accelerate AI adoption in telecoms\",\n",
    "]\n",
    "ids = [\"id1\", \"id2\", \"id3\", \"id4\", \"id5\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4caa2757-1036-4c1d-816f-b8f1961a7385",
   "metadata": {},
   "source": [
    "2. Creating a Chroma Collection\n",
    "A Chroma client is created.\n",
    "\n",
    "A collection named \"Udacity\" is initialized.\n",
    "\n",
    "\n",
    "import chromadb\n",
    "\n",
    "client = chromadb.Client()\n",
    "\n",
    "collection = client.create_collection(name=\"Udacity\")\n",
    "Documents and IDs are added.\n",
    "\n",
    "Default embedding model: all-MiniLM-L6-v2 (via Sentence Transformers).\n",
    "\n",
    "\n",
    "collection.add(documents=sentences, ids=[...])\n",
    "Validation:\n",
    "\n",
    "Number of documents = 5.\n",
    "\n",
    "Peeking into the collection shows embedded vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42d2df62-0883-401d-8abd-cebacf86053d",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client = chromadb.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea523112-291c-419b-9122-6515391863a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To persist in disk, use:\n",
    "# chroma_client = chromadb.PersistentClient(path=\"chromadb/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e56f571-a2e7-4a51-888f-c0a279482a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection = chroma_client.create_collection(name=\"udacity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9229316-75c8-4034-be2a-4acc540f01dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# By default, Chroma uses the Sentence Transformers all-MiniLM-L6-v2 \n",
    "# model to create embeddings.\n",
    "collection.add(\n",
    "    documents=sentence_list,\n",
    "    ids=ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5cf5c0c-14a2-408a-8793-6037b4b48564",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection._embedding_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54270e19-04bf-4eb9-90ef-565c9b37f36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca933318-b941-4906-97a4-725da9551bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.peek(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef9316f2-5129-4b62-a1f4-f25fc7da1972",
   "metadata": {},
   "source": [
    "3. Querying the Vector Database  \n",
    "Queries are performed using keywords like:\n",
    "  \n",
    "\"GPU\"\n",
    "\n",
    "\"CPU\"\n",
    "\n",
    "\"memory\"\n",
    "\n",
    "\"gadget\"\n",
    "\n",
    "Chroma searches based on semantic similarity, returning:\n",
    "\n",
    "Closest matching documents\n",
    "\n",
    "Metadata\n",
    "\n",
    "Distances (similarity scores)\n",
    "  \n",
    "\n",
    "results = collection.query(query_texts=[\"GPU\"], n_results=2)\n",
    "Example result:\n",
    "\n",
    "Top results for \"GPU\" are articles about Intel GPUs and Nvidia acquisitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd3f5a99-78c7-44cb-a21a-f94f70e53c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.query(\n",
    "    query_texts=[\"gadget\"],\n",
    "    n_results=2,\n",
    "    include=['metadatas', 'documents', 'distances']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3222a8dd-81a8-41ab-a742-a07c03900578",
   "metadata": {},
   "source": [
    "4. Changing Embedding Models  \n",
    "A new embedding model all-mpnet-base-v2 is introduced to improve semantic search quality.\n",
    "\n",
    "OpenAI embeddings (text-embedding-ada-002) can also be used.\n",
    "\n",
    "After changing the embedding model:\n",
    "\n",
    "The Udacity collection is deleted and recreated.\n",
    "\n",
    "New embeddings are added.\n",
    "\n",
    "\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_function = SentenceTransformer('all-mpnet-base-v2')\n",
    "Comparisons using dot products show that articles about Nvidia are highly similar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f129ab-d37e-482a-93d3-11e74e0991b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_fn = embedding_functions.SentenceTransformerEmbeddingFunction(\n",
    "    model_name=\"all-mpnet-base-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa913086-a97e-4a25-b265-521ae6d491c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embeddings_fn(sentence_list)\n",
    "len(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf9ca9dd-3a2f-4e4d-9cb3-c988a2e81434",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.dot(embeddings[1], embeddings[4]))\n",
    "print(sentence_list[1])\n",
    "print(sentence_list[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88642945-0dfe-4cc9-a464-149c3205593c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "embeddings_fn = embedding_functions.OpenAIEmbeddingFunction(\n",
    "    api_key=os.getenv(\"OPENAI_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80fafa30-c2a6-4fb4-95c7-fc32536f10ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_fn._model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b62f51-5e6e-45ed-83a9-1f236a78ff02",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client.delete_collection(name=\"udacity\")\n",
    "\n",
    "collection = chroma_client.create_collection(\n",
    "    name=\"udacity\",\n",
    "    embedding_function=embeddings_fn\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbc15b2-87c0-4186-8a7b-de9099d589ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.add(\n",
    "    documents=sentence_list,\n",
    "    ids=ids\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7194371-a80d-47a4-9e20-5ec90ce5493d",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection._embedding_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff31677a-c548-47e4-9753-b6db09d35b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.query(\n",
    "    query_texts=[\"gadget\"],\n",
    "    n_results=2,\n",
    "    include=['metadatas', 'documents', 'distances']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea8b81f-3096-4227-84e7-cc4368ec628e",
   "metadata": {},
   "source": [
    "5. Switching to LangChain Chroma Integration  \n",
    "Instead of using raw Chroma, the demo switches to using Chroma vector stores through LangChain.\n",
    "\n",
    "from langchain.vectorstores import Chroma\n",
    "Documents are created with metadata (e.g., company, topic).\n",
    "\n",
    "Example metadata:  \n",
    "\n",
    "Company: Meta, Topic: Llama\n",
    "\n",
    "Company: Nvidia, Topic: OctoAI\n",
    "\n",
    "\n",
    "docs = [  \n",
    "\n",
    "  Document(page_content=\"...\", metadata={\"company\": \"Meta\", \"topic\": \"Llama\"}),\n",
    "\n",
    "  ...\n",
    "  \n",
    "]  \n",
    "Vector store created with:\n",
    "  \n",
    "Documents\n",
    "\n",
    "Embeddings\n",
    "\n",
    "Persistence to Chroma backend\n",
    "\n",
    "Semantic search with score:\n",
    "\n",
    "Top results are returned with both their text content and similarity scores.\n",
    "\n",
    "vectorstore.similarity_search_with_score(query=\"GPU\", k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7561c2a-30bf-49b6-8389-8ae83e09f7bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "chroma_client.delete_collection(name=\"udacity\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57205641-682d-4972-b030-1dee3e916db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "vector_store = Chroma(\n",
    "    collection_name=\"udacity\",\n",
    "    embedding_function=OpenAIEmbeddings(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8926bb46-b90e-4cda-aadd-b1e21d5cfab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "documents = [\n",
    "    Document(\n",
    "        page_content=\"Meta drops multimodal Llama 3.2 — here's why it's such a big deal\",\n",
    "        metadata={\"company\":\"Meta\", \"topic\": \"llama\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Chip giant Nvidia acquires OctoAI, a Seattle startup that helps companies run AI models\",\n",
    "        metadata={\"company\":\"Nvidia\", \"topic\": \"acquisition\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Google is bringing Gemini to all older Pixel Buds\",\n",
    "        metadata={\"company\":\"Google\", \"topic\": \"gemini\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"The first Intel Battlmage GPU benchmarks have leaked\",\n",
    "        metadata={\"company\":\"Intel\", \"topic\": \"gpu\"}\n",
    "    ),\n",
    "    Document(\n",
    "        page_content=\"Dell partners with Nvidia to accelerate AI adoption in telecoms\",\n",
    "        metadata={\"company\":\"Dell\", \"topic\": \"partnership\"}\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00744ee4-6d64-4cbd-8bf8-d94da1375736",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store.add_documents(documents=documents, ids=ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03f5ed40-db76-44da-8fd2-8e5fcc6f037a",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = vector_store.similarity_search_with_score(query=\"gpu\",k=2)\n",
    "for doc, score in results:\n",
    "    print(f\"-> {doc.page_content}\\n   [Score={score:.2f}]\\n   [{doc.metadata}]\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b8fc4ab-a8e4-4afb-96c1-f349e1b1fe41",
   "metadata": {},
   "source": [
    "6. Key Concepts Highlighted  \n",
    "Vector databases like Chroma are essential for fast semantic search.\n",
    "\n",
    "Embeddings encode meaning; better models yield better search quality.\n",
    "\n",
    "Metadata enhances retrieval by enabling filtered or faceted searches.\n",
    "\n",
    "LangChain integration makes it easy to manage vector stores for downstream tasks.\n",
    "  \n",
    "7. Conclusion  \n",
    "Using ChromaDB (standalone or with LangChain) enables powerful semantic search capabilities.\n",
    "\n",
    "Combining embeddings, persistent storage, and flexible search methods is crucial for real-world RAG (Retrieval-Augmented Generation) and AI systems."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
