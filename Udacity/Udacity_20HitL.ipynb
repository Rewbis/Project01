{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac44cae2-d4f0-4c64-a94b-b077dec367f6",
   "metadata": {},
   "source": [
    "## Summary: Human-in-the-Loop Approvals and Edits in LangGraph Workflows  \n",
    "Overview  \n",
    "This demo introduces human-in-the-loop (HITL) techniques for LangGraph workflows, allowing users to approve, reject, or edit the state before certain actions (like tool calls) proceed. This control mechanism is vital for building safe and supervised AI systems.\n",
    "\n",
    "Key Steps Covered  \n",
    "1. Basic Workflow Structure  \n",
    "a. State Definition\n",
    "The custom state includes:\n",
    "question: str\n",
    "answer: str\n",
    "MessagesState is inherited for managing message history.\n",
    "\n",
    "class State(MessagesState):\n",
    "  question: str\n",
    "  answer: str  \n",
    "b. Nodes\n",
    "Entry Point:\n",
    "Receives the user question and builds system and human messages.\n",
    "Agent Node:\n",
    "Binds the web search tool to the LLM.\n",
    "Invokes the LLM with the current messages.\n",
    "Updates the answer field.\n",
    "def entry_point(state):\n",
    "  ...\n",
    "def agent(state):\n",
    "  ...  \n",
    "c. Router\n",
    "If the latest message contains tool_calls, the workflow proceeds to tools.\n",
    "Otherwise, it terminates.\n",
    "def router(state):\n",
    "  last_message = state[\"messages\"][-1]\n",
    "  return \"tools\" if last_message.tool_calls else END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "254e46cf-f1d7-43e6-9a07-e11c4e7c560d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict\n",
    "from tavily import TavilyClient\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import MessagesState\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from langgraph.graph.state import CompiledStateGraph\n",
    "from langchain_core.messages import AIMessage, HumanMessage, SystemMessage\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9abe80-e3a8-4484-9b1a-1608fb577041",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff476a5-c993-456b-a47a-2ce4683f6cc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def web_search(question:str)->Dict:\n",
    "    \"\"\"\n",
    "    Return top search results for a given search query\n",
    "    \"\"\"\n",
    "    tavily_client = TavilyClient(api_key=os.getenv(\"TAVILY_API_KEY\"))\n",
    "    response = tavily_client.search(question)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768cca74-10ee-46cd-bb88-324dcc9651fc",
   "metadata": {},
   "source": [
    "2. Introducing Breakpoints  \n",
    "During graph compilation, interrupt_before=[\"tools\"] is specified.\n",
    "\n",
    "This pauses the workflow execution before tools are called.\n",
    "\n",
    "Workflow visualization:\n",
    "\n",
    "start → entry_point → agent → [breakpoint] tools → agent → end\n",
    "\n",
    "graph = workflow.compile(interrupt_before=[\"tools\"], checkpointer=memory)\n",
    "Initial example:\n",
    "\n",
    "Question: \"What's the capital of Brazil?\"\n",
    "\n",
    "Workflow pauses after agent identifies a web search is needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22acc644-413b-468c-85b3-3bc0755c0e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class State(MessagesState):\n",
    "    question: str\n",
    "    answer: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dec57d6-03d0-484e-9c94-1d3e91818a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools([web_search])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb889882-b1f2-4a71-896a-689900b80e6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def entry_point(state: State):\n",
    "    question = state[\"question\"]\n",
    "    system_message = SystemMessage(\"You conduct web search to respond to user's questions\")\n",
    "    human_message = HumanMessage(question)\n",
    "    messages = [system_message, human_message]\n",
    "    return {\"messages\": messages}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7089613f-d9bd-484f-88fc-c209d6682b85",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent(state: State):\n",
    "    messages = state[\"messages\"]\n",
    "    ai_message = llm_with_tools.invoke(messages)\n",
    "    return {\"messages\": ai_message, \"answer\": ai_message.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0711c0a9-9df8-4799-bc15-575853ddb1bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def router(state: MessagesState):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "\n",
    "    return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbf08ce-b2b8-4808-bdc2-4f7d5e28ddf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"entry_point\", entry_point)\n",
    "workflow.add_node(\"agent\", agent)\n",
    "workflow.add_node(\"tools\", ToolNode([web_search]))\n",
    "\n",
    "workflow.add_edge(START, \"entry_point\")\n",
    "workflow.add_edge(\"entry_point\", \"agent\")\n",
    "workflow.add_conditional_edges(\n",
    "    source=\"agent\", \n",
    "    path=router, \n",
    "    path_map=[\"tools\", END]\n",
    ")\n",
    "workflow.add_edge(\"tools\", \"agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933dc612-316e-4f0a-8f9e-3aa2d6592bdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()\n",
    "graph = workflow.compile(\n",
    "    interrupt_before=[\"tools\"], \n",
    "    checkpointer=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d030f724-786a-451f-81d4-c853abf239d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    Image(\n",
    "        graph.get_graph().draw_mermaid_png()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d0f0c0a-209a-4f50-8755-ea058e907d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_question = {\"question\": \"what's the capital of Brazil?\"}\n",
    "config = {\"configurable\": {\"thread_id\": 1}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d384d5c7-d92d-48d2-83c0-4ae7a69a01d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in graph.stream(input=input_question, config=config, stream_mode=\"values\"):\n",
    "    if not event['messages']:\n",
    "        continue\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba5d303-86b0-469c-a508-261e8c1bc8a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "state = graph.get_state(config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad7360d-12d5-47cc-81d2-7cf3005d56e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06afc98-21e4-4823-bf74-1e4eb404b017",
   "metadata": {},
   "outputs": [],
   "source": [
    "state.next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c655cf13-1027-4039-bcf4-a8a98748108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for event in graph.stream(input=None, config=config, stream_mode=\"values\"):\n",
    "    if not event['messages']:\n",
    "        continue\n",
    "    event['messages'][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16a1ef1a-c047-4ffe-a87f-33df1b2491c6",
   "metadata": {},
   "source": [
    "## 3. Human Approval Flow  \n",
    "a. Basic Approval  \n",
    "A function human_in_the_loop_run streams the workflow.\n",
    "\n",
    "After seeing the agent’s intent (e.g., to call a tool), the human is prompted:\n",
    "\n",
    "YES: Continue execution.\n",
    "\n",
    "NO: Abort workflow.\n",
    "\n",
    "\n",
    "human_input = input(\"Do you approve the tool calling? (YES or NO): \")\n",
    "Example:\n",
    "\n",
    "Approving → Continues and retrieves the correct answer.\n",
    "\n",
    "Rejecting → Prints \"Workflow aborted by a human.\"\n",
    "\n",
    "b. More Interactive Control (Human Revision)  \n",
    "Workflow is modified to interrupt before the agent instead of tools.\n",
    "\n",
    "If the user says NO to the initial question:\n",
    "\n",
    "They are prompted to edit the question.\n",
    "\n",
    "A system message (\"Workflow edited by a human\") and a new human message are inserted.\n",
    "\n",
    "\n",
    "human_input = input(\"So what should be the question? \")\n",
    "The graph state is updated with the revised input.\n",
    "\n",
    "Execution then resumes from the updated state.\n",
    "\n",
    "Example:\n",
    "\n",
    "Original: \"What’s the capital of Brazil?\"\n",
    "\n",
    "Edit to: \"What’s the capital of Canada?\"\n",
    "\n",
    "Output: \"The capital of Canada is Ottawa.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23b58aea-8636-4a6e-bebc-2a461ddabe5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_in_the_loop_run(graph:CompiledStateGraph, question:str, thread_id:int):\n",
    "    input_question = {\"question\": question}\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    for event in graph.stream(input=input_question, config=config, stream_mode=\"values\"):\n",
    "        if not event['messages']:\n",
    "            continue\n",
    "        event['messages'][-1].pretty_print()\n",
    "    \n",
    "    human_input = input(\"Do you approve the tool calling? (YES or NO): \")\n",
    "    if human_input.lower() == \"yes\":\n",
    "        for event in graph.stream(input=None, config=config, stream_mode=\"values\"):\n",
    "            if not event['messages']:\n",
    "                continue\n",
    "            event['messages'][-1].pretty_print()\n",
    "    \n",
    "    else:\n",
    "        SystemMessage(\"Workflow aborted by a human\").pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9328e45-927f-4243-a3d0-45d97717c09e",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_in_the_loop_run(\n",
    "    graph=graph,\n",
    "    question=\"what's the capital of Brazil?\",\n",
    "    thread_id=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eae12d6-e313-494f-bb7a-f034b602c7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_in_the_loop_run(\n",
    "    graph=graph,\n",
    "    question=\"what's the capital of Mexico?\",\n",
    "    thread_id=3,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6eb1271-7dd7-4727-bd53-6616a21e4750",
   "metadata": {},
   "source": [
    "## 4. Second Human Step After Tool Messages  \n",
    "After a tool call, the human again can:\n",
    "\n",
    "Review.\n",
    "\n",
    "Continue execution.\n",
    "\n",
    "Potentially enhance logic to approve post-tool actions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537553d1-4655-4a08-88ee-5cf256f7e09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = MemorySaver()\n",
    "graph = workflow.compile(\n",
    "    interrupt_before=[\"agent\"], \n",
    "    checkpointer=memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d5741f-03fa-4844-ac69-8657c37382f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    Image(\n",
    "        graph.get_graph().draw_mermaid_png()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92cdfdff-1ad9-4eb5-b5e2-9a6a8d73b2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def human_in_the_loop_run(graph:CompiledStateGraph, question:str, thread_id:int):\n",
    "    input_question = {\"question\": question}\n",
    "    config = {\"configurable\": {\"thread_id\": thread_id}}\n",
    "    for event in graph.stream(input=input_question, config=config, stream_mode=\"values\"):\n",
    "        if not event['messages']:\n",
    "            continue\n",
    "        event['messages'][-1].pretty_print()\n",
    "\n",
    "    human_input = input(\"Do you want to proceed with this question? (YES or NO): \")\n",
    "    \n",
    "    if human_input.lower() == \"no\":\n",
    "        human_input = input(\"So what should be the question? \")\n",
    "        human_message = HumanMessage(content=human_input)\n",
    "        system_message = SystemMessage(\"Workflow edited by a human\")\n",
    "        system_message.pretty_print()\n",
    "        graph.update_state(\n",
    "            config=config,\n",
    "            values={\n",
    "                \"messages\": [\n",
    "                    system_message,\n",
    "                    human_message,\n",
    "                ]\n",
    "            },\n",
    "        )\n",
    "\n",
    "        for event in graph.stream(input=None, config=config, stream_mode=\"values\"):\n",
    "            if not event['messages']:\n",
    "                continue\n",
    "            event['messages'][-1].pretty_print()\n",
    "    \n",
    "    for event in graph.stream(input=None, config=config, stream_mode=\"values\"):\n",
    "        if not event['messages']:\n",
    "            continue\n",
    "        event['messages'][-1].pretty_print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ac5db02-dc64-4146-a5af-b63595ae9482",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_in_the_loop_run(\n",
    "    graph=graph,\n",
    "    question=\"what's the capital of Brazil?\",\n",
    "    thread_id=4,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b466587-d008-41c5-b798-e007299a3a89",
   "metadata": {},
   "outputs": [],
   "source": [
    "human_in_the_loop_run(\n",
    "    graph=graph,\n",
    "    question=\"what's the capital of Brazil?\",\n",
    "    thread_id=5,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef66afe5-28bd-4c16-a1c1-c35328081be3",
   "metadata": {},
   "source": [
    "## 5. Key Concepts Highlighted  \n",
    "Breakpoints allow controlled interruptions during workflows.\n",
    "\n",
    "Human approvals ensure critical actions (like external API calls) can be supervised.\n",
    "\n",
    "Human edits allow correction of user input before significant processing happens.\n",
    "\n",
    "Thread IDs manage session persistence, enabling inspection and modification across sessions.\n",
    "\n",
    "## 6. Conclusion  \n",
    "Human-in-the-loop mechanisms enhance AI system transparency and safety.\n",
    "\n",
    "LangGraph’s breakpoint and checkpoint features make integrating HITL workflows straightforward.\n",
    "\n",
    "A next enhancement would be extending approval loops after tool messages, enabling full-cycle human supervision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb82276-8e27-44cd-9d6a-0fe35445a069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0958e48b-6050-4f6f-8b97-4227f8e2b6bc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
