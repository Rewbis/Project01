{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c89d34f-48c7-4814-84e0-731cc7c3abc7",
   "metadata": {},
   "source": [
    "L1_demo_02_function_calling\n",
    "This demo explores how to use function calling with OpenAIâ€™s chat models while maintaining a memory layer. The system identifies when to use a tool (function), extracts arguments, executes the tool, and feeds the result back into the conversation, enabling a full loop of reasoning and tool use.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feef89a3-c83f-4be4-a661-473503ec1be4",
   "metadata": {},
   "source": [
    "Initial setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "080b50da-0c11-4773-b801-6b65917013d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model count: 84\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from typing import List, Dict, Literal\n",
    "from openai import OpenAI\n",
    "from openai.types.chat.chat_completion_message import ChatCompletionMessage\n",
    "\n",
    "from openai import OpenAI\n",
    "client = OpenAI()  # reads OPENAI_API_KEY from env\n",
    "\n",
    "# Auth + connectivity check\n",
    "models = client.models.list()\n",
    "print(\"Model count:\", len(models.data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09631c36-2f33-48c1-8e6f-89b0db76e338",
   "metadata": {},
   "source": [
    "1. Memory Class Recap and Enhancement\n",
    "A custom Memory class is used to:\n",
    "Add new messages.\n",
    "Fetch all messages.\n",
    "Fetch the last message.\n",
    "Reset the memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8787cded-6e2b-4926-bb19-a01b8e683d21",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Memory:\n",
    "    def __init__(self):\n",
    "        self._messages: List[Dict[str, str]] = []\n",
    "    \n",
    "    def add_message(self, \n",
    "                    role: Literal['user', 'system', 'assistant', 'tool'], \n",
    "                    content: str,\n",
    "                    tool_calls: dict=dict(),\n",
    "                    tool_call_id=None)-> None:\n",
    "\n",
    "        message = {\n",
    "            \"role\": role,\n",
    "            \"content\": content,\n",
    "            \"tool_calls\": tool_calls,\n",
    "        }\n",
    "\n",
    "        if role == \"tool\":\n",
    "            message = {\n",
    "                \"role\": role,\n",
    "                \"content\": content,\n",
    "                \"tool_call_id\": tool_call_id,\n",
    "            }\n",
    "\n",
    "        self._messages.append(message)\n",
    "\n",
    "    def get_messages(self) -> List[Dict[str, str]]:\n",
    "        return self._messages\n",
    "\n",
    "    # A new method\n",
    "    def last_message(self) -> None:\n",
    "        if self._messages:\n",
    "            return self._messages[-1]\n",
    "\n",
    "    # A new method\n",
    "    def reset(self) -> None:\n",
    "        self._messages = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90d88da0-b44d-4c14-af4f-352a862939ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = Memory()\n",
    "memory.add_message(role=\"system\", content=\"You're a helpful assitant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2578d898-940d-4e15-b18c-6c0e750cd8e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': \"You're a helpful assitant\", 'tool_calls': {}}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.get_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a020497e-9c5d-47ab-8685-2d8f61e05019",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ee053fd4-572d-410a-b57c-b05121578e48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.get_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7b2a933-8eae-43f4-92b9-f438d4ca3e04",
   "metadata": {},
   "source": [
    "3. Enhanced Chat Function\n",
    "chat_with_tools is created to:\n",
    "Accept user input and available tools.\n",
    "Pass the tools and memory to the model.\n",
    "Handle tool call outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8eadc0cc-d4aa-4adf-b05c-d761ef9df0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_with_tools(user_question:str=None, \n",
    "                    memory:Memory=None, \n",
    "                    model:str=\"gpt-4o-mini\", \n",
    "                    temperature=0.0, \n",
    "                    tools=None)-> str:\n",
    "    messages = [{\"role\": \"user\", \"content\": user_question}]\n",
    "    if memory:\n",
    "        if user_question:\n",
    "            memory.add_message(role=\"user\", content=user_question)\n",
    "        messages = memory.get_messages()        \n",
    "    \n",
    "    response = client.chat.completions.create(\n",
    "        model = model,\n",
    "        temperature = temperature,\n",
    "        messages = messages,\n",
    "        tools=tools, # Providing available tools to the model\n",
    "    )\n",
    "    \n",
    "    ai_message = str(response.choices[0].message.content)\n",
    "    tool_calls = response.choices[0].message.tool_calls # If the model decides to call a function\n",
    "    \n",
    "    if memory:\n",
    "        memory.add_message(role=\"assistant\", content=ai_message, tool_calls=tool_calls)\n",
    "    \n",
    "    return ai_message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "55ab0fdd-f1ee-4f66-b91d-04b43c7470e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1/32 or 0.03125'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_with_tools(\n",
    "    \"2 to the power of -5?\",\n",
    "    model=\"gpt-3.5-turbo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1fbb762-9857-45d0-85ab-9cbb40738f5c",
   "metadata": {},
   "source": [
    "2. Function Calling Preparation\n",
    "A custom function power(base, exponent) is defined for exponentiation.\n",
    "This function is wrapped in a JSON schema tool description so the model can learn about its existence and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6c0f372-2cee-472e-a36a-84c8b793c7d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def power(base:float, exponent:float):\n",
    "    \"\"\"Exponentatiation: base to the power of exponent\"\"\"\n",
    "    \n",
    "    return base ** exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "00404266-b287-4b47-b823-0cd2c8ceac42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power(2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e16f2323-bed7-4580-92c9-69aceb75ba50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03125"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "power(2, -5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ca24b33-deea-4be4-ab80-ca63fa89e3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [{\n",
    "    \"type\": \"function\",\n",
    "    \"function\": {\n",
    "        \"name\": \"power\",\n",
    "        \"description\": \"Exponentatiation: base to the power of exponent\",\n",
    "        \"parameters\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"base\": {\"type\": \"number\"},\n",
    "                \"exponent\": {\"type\": \"number\"}\n",
    "            },\n",
    "            \"required\": [\"base\", \"exponent\"],\n",
    "            \"additionalProperties\": False\n",
    "        },\n",
    "        \"strict\": True\n",
    "    }\n",
    "}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1641310e-7546-4dbf-b22b-905ff417dedb",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = Memory()\n",
    "memory.add_message(role=\"system\", content=\"You're a helpful assitant\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3795574f-9a99-4b2a-98f3-fd28926ed766",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': \"You're a helpful assitant\", 'tool_calls': {}}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.get_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f9c564f2-cb8b-4271-b6ff-cd1905690956",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_message = chat_with_tools(\n",
    "    \"2 to the power of -5?\",\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    tools=tools,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d8284fa0-15a1-42bb-8531-9bc418980e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': \"You're a helpful assitant\", 'tool_calls': {}},\n",
       " {'role': 'user', 'content': '2 to the power of -5?', 'tool_calls': {}},\n",
       " {'role': 'assistant',\n",
       "  'content': 'None',\n",
       "  'tool_calls': [ChatCompletionMessageFunctionToolCall(id='call_NdedJP9PsvPdj6JeE4scWkFu', function=Function(arguments='{\"base\":2,\"exponent\":-5}', name='power'), type='function')]}]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.get_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d0a5db58-04f4-427c-b858-9209dfdb3b2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ChatCompletionMessageFunctionToolCall(id='call_NdedJP9PsvPdj6JeE4scWkFu', function=Function(arguments='{\"base\":2,\"exponent\":-5}', name='power'), type='function')]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.last_message()['tool_calls']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2e8b5961-aaf3-4d6e-b599-bf0dc0bed959",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'call_NdedJP9PsvPdj6JeE4scWkFu'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tool_call_id = memory.last_message()['tool_calls'][0].id\n",
    "tool_call_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c053f0d-ad88-4162-876b-316c0ee6ff14",
   "metadata": {},
   "source": [
    "4. Flow of Execution\n",
    "The model receives a query like \"2^-5\".\n",
    "Instead of responding directly, it outputs a tool call:\n",
    "Function name: power\n",
    "Arguments: base=2, exponent=-5\n",
    "Developer extracts these arguments, executes the power function manually, and stores the result.\n",
    "A new tool role message is added to the memory, linking it to the original tool call ID."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9bdd8c88-8160-4f23-8f28-62bc426d2e7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'base': 2, 'exponent': -5}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "args = json.loads(memory.last_message()['tool_calls'][0].function.arguments)\n",
    "args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a33115d-d407-4db8-9b01-c6ea76c3830c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03125"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = power(args[\"base\"], args[\"exponent\"])\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "11966ba3-f0a5-4651-9255-70d08220efb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory.add_message(role=\"tool\", content=str(result), tool_call_id=tool_call_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "74b5a507-3689-48f8-8513-5798dcbafa34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': \"You're a helpful assitant\", 'tool_calls': {}},\n",
       " {'role': 'user', 'content': '2 to the power of -5?', 'tool_calls': {}},\n",
       " {'role': 'assistant',\n",
       "  'content': 'None',\n",
       "  'tool_calls': [ChatCompletionMessageFunctionToolCall(id='call_NdedJP9PsvPdj6JeE4scWkFu', function=Function(arguments='{\"base\":2,\"exponent\":-5}', name='power'), type='function')]},\n",
       " {'role': 'tool',\n",
       "  'content': '0.03125',\n",
       "  'tool_call_id': 'call_NdedJP9PsvPdj6JeE4scWkFu'}]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.get_messages()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "765c6195-d3e9-4087-a387-71541aae21b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "ai_message = chat_with_tools(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    tools=tools,\n",
    "    memory=memory,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "e026dd1b-6e98-46c4-99ca-c866863a18b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'role': 'system', 'content': \"You're a helpful assitant\", 'tool_calls': {}},\n",
       " {'role': 'user', 'content': '2 to the power of -5?', 'tool_calls': {}},\n",
       " {'role': 'assistant',\n",
       "  'content': 'None',\n",
       "  'tool_calls': [ChatCompletionMessageFunctionToolCall(id='call_NdedJP9PsvPdj6JeE4scWkFu', function=Function(arguments='{\"base\":2,\"exponent\":-5}', name='power'), type='function')]},\n",
       " {'role': 'tool',\n",
       "  'content': '0.03125',\n",
       "  'tool_call_id': 'call_NdedJP9PsvPdj6JeE4scWkFu'},\n",
       " {'role': 'assistant',\n",
       "  'content': '2 to the power of -5 is 0.03125',\n",
       "  'tool_calls': None}]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "memory.get_messages()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da73bda3-7acd-49de-9abb-3163ae5bf9bb",
   "metadata": {},
   "source": [
    "5. Final AI Response\n",
    "After feeding back the toolâ€™s result, the model is invoked again.\n",
    "Now, the assistant produces a natural language response incorporating the toolâ€™s output (e.g., \"2 to the power of -5 is approximately 0.031\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "538ce0ae-cb5d-4c15-bab6-fabc396d0483",
   "metadata": {},
   "source": [
    "6. Key Concepts Highlighted\n",
    "The difference between standard responses and tool call behavior.\n",
    "How function calling allows LLMs to extend their capabilities.\n",
    "Importance of linking tool responses back via tool_call_id.\n",
    "How memory tracks both user interactions and intermediate tool operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b27fc4-aad1-41ec-9367-20349f98945c",
   "metadata": {},
   "source": [
    "7. Conclusion\n",
    "Function calling enables a much more structured and powerful interaction loop.\n",
    "The memory structure supports complex multi-turn conversations that involve external tool use.\n",
    "Proper handling of tool call and tool response messages is crucial for building advanced AI agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec9fede5-779e-4bfb-8c42-776ebf544bcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
