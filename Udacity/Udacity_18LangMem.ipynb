{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "70010070-8f62-498b-95e9-4386c5b52996",
   "metadata": {},
   "source": [
    "## Summary: Building Long-Term Memory with LangMem  \n",
    "Overview  \n",
    "This demo explains how to combine vector database storage with an agent framework to create long-term memory using LangMem, a library built by the LangChain team. The goal is to enable agents to remember facts across multiple interactions.\n",
    "\n",
    "Key Steps Covered  \n",
    "1. Setting up LangMem  \n",
    "LangMem handles the memory store behind the scenes, using vector embeddings to save and retrieve information.\n",
    "\n",
    "Memory storage is backed by OpenAI embeddings in this example.\n",
    "\n",
    "\n",
    "from langmem import OpenAIMemoryStore\n",
    "\n",
    "store = OpenAIMemoryStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d664f1e-8b24-40e0-914d-10cd6ec191e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import create_react_agent\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langmem import create_manage_memory_tool, create_search_memory_tool\n",
    "from langchain_core.messages import HumanMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54585bb8-523a-4f59-b313-15e78860b855",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49f11e4a-7d1a-462e-944f-c6f72f771bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "store = InMemoryStore(\n",
    "    index={\n",
    "        \"dims\": 1536,\n",
    "        \"embed\": \"openai:text-embedding-3-small\",\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9e02b1-dd7c-41b5-9504-5f3867faecce",
   "metadata": {},
   "source": [
    "## 2. Creating the Workflow  \n",
    "A ReAct agent is created using a prebuilt LangMem utility:\n",
    "\n",
    "create_react_agent(model, tools, store)\n",
    "No custom StateSchema is needed.\n",
    "\n",
    "Two tools are defined:  \n",
    "\n",
    "manage_memory_tool: Saves information into the store.\n",
    "\n",
    "search_memory_tool: Retrieves information from the store.\n",
    "\n",
    "\n",
    "tools = [manage_memory_tool, search_memory_tool]\n",
    "\n",
    "agent = create_react_agent(model=llm, tools=tools, store=store)\n",
    "The agent workflow:\n",
    "\n",
    "Agent node → Tools node → Agent node → End"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a0bde72-c4e1-4ea8-a23e-256ae732b68d",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = create_react_agent(\n",
    "    model=\"openai:gpt-4o-mini\",\n",
    "    tools=[\n",
    "        # Memory tools use LangGraph's BaseStore for persistence\n",
    "        create_manage_memory_tool(namespace=(\"memories\",)),\n",
    "        create_search_memory_tool(namespace=(\"memories\",)),\n",
    "    ],\n",
    "    store=store,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e579bb77-3b5d-4a06-b6a2-ab6e3af93bf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f36c7da6-2d05-4e3e-9919-d70b948a9f37",
   "metadata": {},
   "source": [
    "## 3. Inspecting the Input Schema  \n",
    "The input schema for the agent expects a field called messages.\n",
    "\n",
    "messages should include:  \n",
    "\n",
    "SystemMessage\n",
    "\n",
    "HumanMessage\n",
    "\n",
    "AIMessage\n",
    "\n",
    "ToolMessages (after tool calls)\n",
    "\n",
    "\n",
    "{\n",
    "\n",
    "  \"messages\": [...]\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f570829a-4b41-4ae1-b4da-1d6b8a7aa6df",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.get_input_jsonschema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2db16115-b17d-48d6-b359-23ca4a9810a3",
   "metadata": {},
   "source": [
    "## 4. Example Interaction: Setting and Retrieving Preferences  \n",
    "a. Initial Question\n",
    "User asks:  \n",
    "\n",
    "\"What are my lighting preferences?\"  \n",
    "The agent:  \n",
    "\n",
    "Calls the search_memory tool.\n",
    "\n",
    "Tool responds: No memory found.\n",
    "\n",
    "Agent replies: \"I don't have any information about your lighting preferences.\"\n",
    "  \n",
    "b. Saving New Information\n",
    "User follows up:\n",
    "  \n",
    "\"Remember that I prefer dark mode.\"  \n",
    "The agent:\n",
    "\n",
    "Calls the manage_memory tool.\n",
    "\n",
    "Saves the new preference into the store.\n",
    "\n",
    "Replies: \"I've noted that you prefer dark mode.\"\n",
    "  \n",
    "c. New Session Retrieval\n",
    "A new thread is started with a fresh message:\n",
    "\n",
    "\"What are my lighting preferences?\"\n",
    "Only this question is provided (no prior conversation).\n",
    "\n",
    "The agent:\n",
    "\n",
    "Calls the search_memory tool.\n",
    "\n",
    "Finds the saved memory from the previous interaction.\n",
    "  \n",
    "Replies correctly: \"You prefer dark mode.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ce20eb-3850-42d2-a26f-422477393d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask a random question to the agent\n",
    "output = agent.invoke(\n",
    "    input = {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": \"What are my lighting preferences?\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    ")\n",
    "\n",
    "output['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc515ad0-5a5d-4b76-999f-660ef40f32da",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = output['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7794609-7b30-4545-8756-1e3f7a705b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(HumanMessage(\"Ok. Remember that I prefer dark mode.\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45f0f3e-9c2f-449d-aca1-6e7f5ca83383",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store a new memory in one Session\n",
    "output = agent.invoke(\n",
    "    input = {\n",
    "        \"messages\": messages,\n",
    "    },\n",
    "    config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    ")\n",
    "\n",
    "output['messages']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "734eb703-02da-4b1f-86ab-a0ad73839f4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the stored memory in another Session\n",
    "output = agent.invoke(\n",
    "    {\n",
    "        \"messages\": [\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": \"What are my lighting preferences?\"\n",
    "            }\n",
    "        ]\n",
    "    },\n",
    "    config = {\"configurable\": {\"thread_id\": \"2\"}}\n",
    ")\n",
    "\n",
    "output['messages']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c6afdf1-2966-4590-aac7-4b0a4f50718c",
   "metadata": {},
   "source": [
    "## 5. Key Concepts Highlighted  \n",
    "Persistent memory across different sessions and thread IDs.\n",
    "\n",
    "Memory search and management handled with tools abstracted from the agent's reasoning.\n",
    "\n",
    "Vector-based retrieval ensures memory is stored in a scalable, semantically searchable format.\n",
    "\n",
    "The user does not need to manually maintain history; it's offloaded to LangMem.\n",
    "  \n",
    "## 6. Conclusion  \n",
    "LangMem makes it easy to extend ReAct agents with long-term memory.\n",
    "\n",
    "Agents can now recall user preferences or facts across completely different conversations.\n",
    "\n",
    "This memory-enhanced design is a key step toward building more lifelike, persistent AI agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bda6ed2-dd5c-4b88-a256-8707cb9fcd72",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bcef577-15b4-41dc-95c0-c7ea396d8baa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8670e029-7419-4094-9045-eb84f6e2fb7c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009dd53a-b17a-48b6-9c37-f9332a748c6f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22e11707-8536-4bf6-971e-336229061756",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "294695b8-d6ee-41bd-9f1a-1fffd404b5c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa46d5c-7a2f-47d1-a98e-fa109b04cce9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c284b0ea-8e81-416e-a3a3-748d78f35c4d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d06cb28-3091-4474-a22f-34609fd36d1a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
