{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dcb0892e-9505-4924-81bb-e3f429aec5ae",
   "metadata": {},
   "source": [
    "Knowledge Base Agents and Reliability\n",
    "Building effective AI agents requires expanding their knowledge sources and ensuring they function reliably in real-world applications. Whether developing a customer support bot or a complex AI assistant, agents need access to accurate data and well-structured workflows to improve their performance.\n",
    "\n",
    "Expanding an Agent’s Knowledge\n",
    "Agents can go beyond simple LLM-powered responses by integrating external data sources.\n",
    "\n",
    "APIs – Provide real-time data, allowing agents to access updated information.\n",
    "Long-Term Memory – Enables agents to store and recall past interactions by saving data in a database.\n",
    "Retrieval-Augmented Generation (RAG) – Enhances agents by retrieving relevant knowledge before generating a response.\n",
    "Designing for Reliability\n",
    "Reliability means ensuring an agent performs its intended function efficiently and safely. Several factors must be considered:\n",
    "\n",
    "Defining the Agent’s Role – Should an agent handle multiple tasks, or should there be specialized agents with clear objectives?\n",
    "Measuring Performance – Is the agent efficient? If a task takes 10 minutes and thousands of tokens, it may need optimization.\n",
    "Assessing Success Probability – Establish evaluation criteria before deploying an agent.\n",
    "Understanding the Operational Environment – A banking agent assisting investors may require a different workflow than one advising loan applicants.\n",
    "Preventing Harm – Restrict agent permissions to avoid critical failures, such as deleting an entire database table.\n",
    "Techniques for Improving Reliability\n",
    "Human-in-the-Loop – In critical cases, human oversight ensures correctness.\n",
    "Observability – Tracking response time, accuracy, and user interactions helps in optimizing agent behavior.\n",
    "Evaluation – Unlike traditional ML models, agentic systems require continuous, iterative evaluation to maintain quality.\n",
    "Final Thoughts\n",
    "AI applications must be designed for reliability by carefully structuring workflows, integrating external knowledge sources, and implementing best practices. In the next lesson, these concepts will be applied using LangGraph."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391e13d2-3a7b-45d7-a564-a44a7ea7b897",
   "metadata": {},
   "source": [
    "Enhancing an Agent’s Knowledge\n",
    "An agent’s knowledge can be improved by optimizing its internal components. These can be grouped into three categories:\n",
    "\n",
    "Understanding – How well the underlying model interprets and reasons about user inputs.\n",
    "Context – Additional instructions or external data provided to shape the agent’s responses.\n",
    "Memory – Storage and retrieval of past interactions to ensure continuity across conversations.\n",
    "Understanding\n",
    "An LLM processes language by predicting the most probable next token, enabling it to interpret inputs and adapt to different situations.\n",
    "\n",
    "Ways to improve understanding:\n",
    "\n",
    "Use a larger model with more training data and better reasoning capabilities.\n",
    "Fine-tune a model with high-quality, domain-specific data to enhance performance in a particular field.\n",
    "A strong underlying model ensures the agent can handle diverse queries and make informed decisions.\n",
    "\n",
    "Context\n",
    "Context enhances an agent’s decision-making by providing background information and external tools.\n",
    "\n",
    "Ways of adding context:\n",
    "\n",
    "System Prompts – Provide procedural guidelines.\n",
    "Few-Shot Prompting – Supplies examples of how to respond to specific inputs, improving behavior.\n",
    "Tool Use – Allows the model to select and call external functions when needed.\n",
    "Knowledge Bases (RAG) – Uses Retrieval-Augmented Generation to fetch relevant documents, reducing the need for complex prompts.\n",
    "Memory\n",
    "Since LLMs are stateless, they do not remember past interactions unless memory is explicitly managed.\n",
    "\n",
    "Types of memory storage:\n",
    "\n",
    "Short-Term Memory – Maintains conversation continuity within a single interaction loop but resets once the loop ends.\n",
    "\n",
    "In-Session Memory – Stores conversation history for the duration of a session, allowing multi-turn interactions.\n",
    "\n",
    "Across-Session Memory – Retains long-term knowledge of past user interactions, preferences, or previous agent actions across multiple sessions.\n",
    "\n",
    "Balancing Knowledge and Cost\n",
    "While adding context and memory improves agent performance, it comes with trade-offs:\n",
    "\n",
    "Stateless models require full context for every invocation.\n",
    "Token limits restrict how much information can be included in a prompt.\n",
    "Larger models and longer prompts increase computational costs.\n",
    "Effective AI workflow design requires balancing context, memory, and efficiency to create knowledgeable and scalable agents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3f2e91-96d6-41fa-8d4f-b4f612f2a0de",
   "metadata": {},
   "source": [
    "Summary: Calling External APIs with Tools in LangGraph Workflows\n",
    "Overview\n",
    "This demo explains how to integrate external API calls into LangGraph workflows by building custom tools. It highlights the use of real-time data retrieval (quotes and web search) and shows how agents interact with external information sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff8bd16c-c24f-46e5-920b-e8b2f0ae0e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from typing import Dict\n",
    "import requests\n",
    "from tavily import TavilyClient\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.messages import (\n",
    "    SystemMessage,\n",
    "    AIMessage,\n",
    "    HumanMessage, \n",
    "    ToolMessage,\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.graph.message import MessagesState, add_messages\n",
    "from langgraph.prebuilt import ToolNode\n",
    "from IPython.display import Image, display\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b7ba224f-0c03-4452-8afd-9b744d09bfa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3cb28a3-bac3-4c33-ab0a-c8bd13ca4a6c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2a19575-b0a4-4ee8-aa5b-059374c9d260",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "# won't work within ACN - website restricted\n",
    "def random_got_quote_tool()->Dict:\n",
    "    \"\"\"\n",
    "    Return a random Game of Thrones quote and the character who said it\n",
    "    \"\"\"\n",
    "    response = requests.get(\"https://api.gameofthronesquotes.xyz/v1/random\")\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "114d72df-cea7-44bd-85d2-0a1dd175aa0b",
   "metadata": {},
   "outputs": [
    {
     "ename": "SSLError",
     "evalue": "HTTPSConnectionPool(host='api.gameofthronesquotes.xyz', port=443): Max retries exceeded with url: /v1/random (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1032)')))",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mSSLCertVerificationError\u001b[39m                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\PythonProjects\\Project01\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:464\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\PythonProjects\\Project01\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:1093\u001b[39m, in \u001b[36mHTTPSConnectionPool._validate_conn\u001b[39m\u001b[34m(self, conn)\u001b[39m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m conn.is_closed:\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\PythonProjects\\Project01\\.venv\\Lib\\site-packages\\urllib3\\connection.py:741\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    739\u001b[39m server_hostname_rm_dot = server_hostname.rstrip(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m741\u001b[39m sock_and_verified = \u001b[43m_ssl_wrap_socket_and_match_hostname\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    742\u001b[39m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    743\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    744\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    745\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    746\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    747\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    748\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    749\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    750\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    752\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    753\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname_rm_dot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    754\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    755\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    756\u001b[39m \u001b[43m    \u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    757\u001b[39m \u001b[43m    \u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    758\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    759\u001b[39m \u001b[38;5;28mself\u001b[39m.sock = sock_and_verified.socket\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\PythonProjects\\Project01\\.venv\\Lib\\site-packages\\urllib3\\connection.py:920\u001b[39m, in \u001b[36m_ssl_wrap_socket_and_match_hostname\u001b[39m\u001b[34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[39m\n\u001b[32m    918\u001b[39m         server_hostname = normalized\n\u001b[32m--> \u001b[39m\u001b[32m920\u001b[39m ssl_sock = \u001b[43mssl_wrap_socket\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeyfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcertfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\PythonProjects\\Project01\\.venv\\Lib\\site-packages\\urllib3\\util\\ssl_.py:460\u001b[39m, in \u001b[36mssl_wrap_socket\u001b[39m\u001b[34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[39m\n\u001b[32m    458\u001b[39m context.set_alpn_protocols(ALPN_PROTOCOLS)\n\u001b[32m--> \u001b[39m\u001b[32m460\u001b[39m ssl_sock = \u001b[43m_ssl_wrap_socket_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ssl_sock\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\PythonProjects\\Project01\\.venv\\Lib\\site-packages\\urllib3\\util\\ssl_.py:504\u001b[39m, in \u001b[36m_ssl_wrap_socket_impl\u001b[39m\u001b[34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[39m\n\u001b[32m    502\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m SSLTransport(sock, ssl_context, server_hostname)\n\u001b[32m--> \u001b[39m\u001b[32m504\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mssl_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python\\Lib\\ssl.py:455\u001b[39m, in \u001b[36mSSLContext.wrap_socket\u001b[39m\u001b[34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[39m\n\u001b[32m    449\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    450\u001b[39m                 do_handshake_on_connect=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    451\u001b[39m                 suppress_ragged_eofs=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    452\u001b[39m                 server_hostname=\u001b[38;5;28;01mNone\u001b[39;00m, session=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    453\u001b[39m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[32m    454\u001b[39m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m455\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msslsocket_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    456\u001b[39m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    458\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    459\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    460\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    461\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    462\u001b[39m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[43m=\u001b[49m\u001b[43msession\u001b[49m\n\u001b[32m    463\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python\\Lib\\ssl.py:1076\u001b[39m, in \u001b[36mSSLSocket._create\u001b[39m\u001b[34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[39m\n\u001b[32m   1075\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1076\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1077\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Python\\Lib\\ssl.py:1372\u001b[39m, in \u001b[36mSSLSocket.do_handshake\u001b[39m\u001b[34m(self, block)\u001b[39m\n\u001b[32m   1371\u001b[39m         \u001b[38;5;28mself\u001b[39m.settimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1372\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1373\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[31mSSLCertVerificationError\u001b[39m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1032)",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mSSLError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\PythonProjects\\Project01\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\PythonProjects\\Project01\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:488\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    487\u001b[39m         new_e = _wrap_proxy_error(new_e, conn.proxy.scheme)\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[32m    490\u001b[39m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[32m    491\u001b[39m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
      "\u001b[31mSSLError\u001b[39m: [SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1032)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mMaxRetryError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\PythonProjects\\Project01\\.venv\\Lib\\site-packages\\requests\\adapters.py:644\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    643\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m644\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    645\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    646\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    648\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    649\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    650\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    651\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    652\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    653\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    654\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    655\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    656\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    658\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\PythonProjects\\Project01\\.venv\\Lib\\site-packages\\urllib3\\connectionpool.py:841\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    839\u001b[39m     new_e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, new_e)\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m retries.sleep()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\PythonProjects\\Project01\\.venv\\Lib\\site-packages\\urllib3\\util\\retry.py:519\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    518\u001b[39m     reason = error \u001b[38;5;129;01mor\u001b[39;00m ResponseError(cause)\n\u001b[32m--> \u001b[39m\u001b[32m519\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m MaxRetryError(_pool, url, reason) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mreason\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    521\u001b[39m log.debug(\u001b[33m\"\u001b[39m\u001b[33mIncremented Retry for (url=\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m): \u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[33m\"\u001b[39m, url, new_retry)\n",
      "\u001b[31mMaxRetryError\u001b[39m: HTTPSConnectionPool(host='api.gameofthronesquotes.xyz', port=443): Max retries exceeded with url: /v1/random (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1032)')))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[31mSSLError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mrandom_got_quote_tool\u001b[49m\u001b[43m.\u001b[49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\PythonProjects\\Project01\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:607\u001b[39m, in \u001b[36mBaseTool.invoke\u001b[39m\u001b[34m(self, input, config, **kwargs)\u001b[39m\n\u001b[32m    599\u001b[39m \u001b[38;5;129m@override\u001b[39m\n\u001b[32m    600\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34minvoke\u001b[39m(\n\u001b[32m    601\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    604\u001b[39m     **kwargs: Any,\n\u001b[32m    605\u001b[39m ) -> Any:\n\u001b[32m    606\u001b[39m     tool_input, kwargs = _prep_run_args(\u001b[38;5;28minput\u001b[39m, config, **kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m607\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtool_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\PythonProjects\\Project01\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:892\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    890\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m error_to_raise:\n\u001b[32m    891\u001b[39m     run_manager.on_tool_error(error_to_raise)\n\u001b[32m--> \u001b[39m\u001b[32m892\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m error_to_raise\n\u001b[32m    893\u001b[39m output = _format_output(content, artifact, tool_call_id, \u001b[38;5;28mself\u001b[39m.name, status)\n\u001b[32m    894\u001b[39m run_manager.on_tool_end(output, color=color, name=\u001b[38;5;28mself\u001b[39m.name, **kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\PythonProjects\\Project01\\.venv\\Lib\\site-packages\\langchain_core\\tools\\base.py:861\u001b[39m, in \u001b[36mBaseTool.run\u001b[39m\u001b[34m(self, tool_input, verbose, start_color, color, callbacks, tags, metadata, run_name, run_id, config, tool_call_id, **kwargs)\u001b[39m\n\u001b[32m    859\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config_param := _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m._run):\n\u001b[32m    860\u001b[39m         tool_kwargs |= {config_param: config}\n\u001b[32m--> \u001b[39m\u001b[32m861\u001b[39m     response = \u001b[43mcontext\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_run\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43mtool_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtool_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    862\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.response_format == \u001b[33m\"\u001b[39m\u001b[33mcontent_and_artifact\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    863\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response, \u001b[38;5;28mtuple\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(response) != \u001b[32m2\u001b[39m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\PythonProjects\\Project01\\.venv\\Lib\\site-packages\\langchain_core\\tools\\structured.py:103\u001b[39m, in \u001b[36mStructuredTool._run\u001b[39m\u001b[34m(self, config, run_manager, *args, **kwargs)\u001b[39m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m config_param := _get_runnable_config_param(\u001b[38;5;28mself\u001b[39m.func):\n\u001b[32m    102\u001b[39m         kwargs[config_param] = config\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    104\u001b[39m msg = \u001b[33m\"\u001b[39m\u001b[33mStructuredTool does not support sync invocation.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    105\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(msg)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 6\u001b[39m, in \u001b[36mrandom_got_quote_tool\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;129m@tool\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrandom_got_quote_tool\u001b[39m()->Dict:\n\u001b[32m      3\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[33;03m    Return a random Game of Thrones quote and the character who said it\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     response = \u001b[43mrequests\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mhttps://api.gameofthronesquotes.xyz/v1/random\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      7\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m response.json()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\PythonProjects\\Project01\\.venv\\Lib\\site-packages\\requests\\api.py:73\u001b[39m, in \u001b[36mget\u001b[39m\u001b[34m(url, params, **kwargs)\u001b[39m\n\u001b[32m     62\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget\u001b[39m(url, params=\u001b[38;5;28;01mNone\u001b[39;00m, **kwargs):\n\u001b[32m     63\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33mr\u001b[39m\u001b[33;03m\"\"\"Sends a GET request.\u001b[39;00m\n\u001b[32m     64\u001b[39m \n\u001b[32m     65\u001b[39m \u001b[33;03m    :param url: URL for the new :class:`Request` object.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     70\u001b[39m \u001b[33;03m    :rtype: requests.Response\u001b[39;00m\n\u001b[32m     71\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m73\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mget\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m=\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\PythonProjects\\Project01\\.venv\\Lib\\site-packages\\requests\\api.py:59\u001b[39m, in \u001b[36mrequest\u001b[39m\u001b[34m(method, url, **kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# By using the 'with' statement we are sure the session is closed, thus we\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[38;5;66;03m# avoid leaving sockets open which can trigger a ResourceWarning in some\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[38;5;66;03m# cases, and look like a memory leak in others.\u001b[39;00m\n\u001b[32m     58\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m sessions.Session() \u001b[38;5;28;01mas\u001b[39;00m session:\n\u001b[32m---> \u001b[39m\u001b[32m59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\PythonProjects\\Project01\\.venv\\Lib\\site-packages\\requests\\sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    584\u001b[39m send_kwargs = {\n\u001b[32m    585\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mtimeout\u001b[39m\u001b[33m\"\u001b[39m: timeout,\n\u001b[32m    586\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mallow_redirects\u001b[39m\u001b[33m\"\u001b[39m: allow_redirects,\n\u001b[32m    587\u001b[39m }\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\PythonProjects\\Project01\\.venv\\Lib\\site-packages\\requests\\sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m start = preferred_clock()\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n\u001b[32m    706\u001b[39m elapsed = preferred_clock() - start\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\PythonProjects\\Project01\\.venv\\Lib\\site-packages\\requests\\adapters.py:675\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    671\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m ProxyError(e, request=request)\n\u001b[32m    673\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e.reason, _SSLError):\n\u001b[32m    674\u001b[39m         \u001b[38;5;66;03m# This branch is for urllib3 v1.22 and later.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m675\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m SSLError(e, request=request)\n\u001b[32m    677\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e, request=request)\n\u001b[32m    679\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ClosedPoolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[31mSSLError\u001b[39m: HTTPSConnectionPool(host='api.gameofthronesquotes.xyz', port=443): Max retries exceeded with url: /v1/random (Caused by SSLError(SSLCertVerificationError(1, '[SSL: CERTIFICATE_VERIFY_FAILED] certificate verify failed: self-signed certificate in certificate chain (_ssl.c:1032)')))"
     ]
    }
   ],
   "source": [
    "random_got_quote_tool.invoke({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd979dc-458e-44b7-9b7f-0eda9f09295c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tavily_client = TavilyClient(\n",
    "    api_key=os.getenv(\"TAVILY_API_KEY\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4260fa5-8926-4b6a-b0ec-8df45c809ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def web_search(question:str)->Dict:\n",
    "    \"\"\"\n",
    "    Return top search results for a given search query\n",
    "    \"\"\"\n",
    "    response = tavily_client.search(question)\n",
    "    return response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f587b7c3-8138-4493-afc7-cbdcaa433a85",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_search.invoke(\n",
    "    {\n",
    "        \"question\": \"Who performs Cersei Lannister in Game of Thrones?\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82c8bf8-08b5-4ae9-aecf-61d642eb59ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [random_got_quote_tool, web_search]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb94e877-0ed2-4510-aa2a-6d6d41793f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "849ba50b-3b0e-41c7-934d-c839751d5d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0862c626-1588-424f-86f5-9ff80f689915",
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent(state: MessagesState):\n",
    "    ai_message = llm_with_tools.invoke(state[\"messages\"])\n",
    "    return {\"messages\": ai_message}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fcd7834-0efd-481b-b6e8-41c2a7b51380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def router(state: MessagesState):\n",
    "    last_message = state[\"messages\"][-1]\n",
    "    if last_message.tool_calls:\n",
    "        return \"tools\"\n",
    "\n",
    "    return END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "451269dc-47f0-44b8-ad13-1bcd0d403da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "workflow.add_node(\"agent\", agent)\n",
    "workflow.add_node(\"tools\", ToolNode(tools))\n",
    "\n",
    "workflow.add_edge(START, \"agent\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    source=\"agent\", \n",
    "    path=router, \n",
    "    path_map=[\"tools\", END]\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"tools\", \"agent\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "472a647c-a1a3-42a7-8898-5b2f9cb1539f",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = workflow.compile()\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        graph.get_graph().draw_mermaid_png()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec6a2516-0636-4b2a-b4b2-42940e9b0567",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = [\n",
    "    SystemMessage(\n",
    "        \"You are a Web Researcher focused on Game of Thrones. \"\n",
    "        \"If user asks you a random quote about GoT. You will not only \" \n",
    "        \"provide it, but also search the web to find the actor or actress \"\n",
    "        \"who perform the character who said that.\"\n",
    "        \"So, your output should be: Quote, Character and Performer.\"\n",
    "    ),\n",
    "    HumanMessage(\"Give me a radom GoT quote\")\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc07ed2f-7183-465d-adca-91dab0bda098",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = graph.invoke(\n",
    "    input={\n",
    "        \"messages\": messages\n",
    "    }\n",
    ")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82596ac-77cd-4042-adc5-97237b100b7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for message in result[\"messages\"]:\n",
    "    message.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6a1cf2-84fb-4e76-9af3-4239ae1dc35c",
   "metadata": {},
   "source": [
    "Key Steps Covered\n",
    "1. Setting up External API Tools\n",
    "a. Random Game of Thrones Quote Tool\n",
    "A tool is created to fetch a random Game of Thrones quote.\n",
    "\n",
    "Uses a public API endpoint (https://api.gameofthronesquotes.xyz/v1/random).\n",
    "\n",
    "\n",
    "@tool\n",
    "\n",
    "def random_got_quote():\n",
    "\n",
    "  response = requests.get(\"https://api.gameofthronesquotes.xyz/v1/random\")\n",
    "\n",
    "  return response.json()\n",
    "Sample outputs include:\n",
    "\n",
    "\"sentence\": \"The things I do for love.\"\n",
    "\n",
    "\"character\": \"Jaime Lannister\"\n",
    "\n",
    "b. Tavily Web Search Tool\n",
    "A second tool is built for live web search using the Tavily API.\n",
    "\n",
    "Allows answering follow-up questions based on current information.\n",
    "\n",
    "\n",
    "@tool\n",
    "\n",
    "def web_search(question: str):\n",
    "\n",
    "  response = tavily_client.search(query=question)\n",
    "\n",
    "  return response\n",
    "Example use:\n",
    "\n",
    "Question: \"Who performs Cersei Lannister in Game of Thrones?\"\n",
    "\n",
    "Top result: \"Lena Headey\" from Wikipedia.\n",
    "\n",
    "2. Binding Tools to the LLM\n",
    "The tools are bound to the LLM using bind_tools.\n",
    "\n",
    "This creates an LLM with Tools object.\n",
    "\n",
    "\n",
    "llm_with_tools = llm.bind_tools([random_got_quote, web_search])\n",
    "An agent abstraction is built around the LLM with tools.\n",
    "3. Router Logic\n",
    "A router determines if tool usage is necessary:\n",
    "\n",
    "If the last message includes a tool call, the workflow routes to the tools node.\n",
    "\n",
    "Otherwise, it terminates.\n",
    "\n",
    "\n",
    "def router(state):\n",
    "\n",
    "  last_message = state.messages[-1]\n",
    "\n",
    "  if last_message.tool_calls:\n",
    "\n",
    "      return \"tools\"\n",
    "\n",
    "  return \"end\"\n",
    "4. Workflow Construction\n",
    "A LangGraph StateGraph is set up using MessageState to manage conversation history.\n",
    "\n",
    "Nodes:\n",
    "\n",
    "agent node: Handles standard LLM interaction.\n",
    "\n",
    "tools node: Executes the external API tool calls.\n",
    "\n",
    "Edges:\n",
    "\n",
    "start → agent\n",
    "\n",
    "agent → tools (conditionally, if needed)\n",
    "\n",
    "tools → agent (loop)\n",
    "\n",
    "Terminate when no tool calls are made.\n",
    "\n",
    "\n",
    "workflow.add_node(\"agent\", agent_node)\n",
    "\n",
    "workflow.add_node(\"tools\", tools_node)\n",
    "\n",
    "workflow.add_edge(\"start\", \"agent\")\n",
    "\n",
    "workflow.add_conditional_edges(\"agent\", router)\n",
    "\n",
    "workflow.add_edge(\"tools\", \"agent\")\n",
    "5. Execution Example\n",
    "System sets the agent’s personality: \"You are a web researcher focused on Game of Thrones.\"\n",
    "\n",
    "Human asks: \"Give me a random Game of Thrones quote.\"\n",
    "\n",
    "Flow:\n",
    "\n",
    "Agent calls random_got_quote.\n",
    "\n",
    "Receives a quote (e.g., by Jaime Lannister).\n",
    "\n",
    "Agent decides it needs to find the actor.\n",
    "\n",
    "Calls web_search for \"Jaime Lannister actor.\"\n",
    "\n",
    "Receives result: \"Nikolaj Coster-Waldau.\"\n",
    "\n",
    "Outputs:\n",
    "\n",
    "Sentence\n",
    "\n",
    "Character\n",
    "\n",
    "Actor\n",
    "\n",
    "Associated URLs for more information.\n",
    "\n",
    "6. Key Concepts Highlighted\n",
    "Tool integration enables real-time, dynamic retrieval of external data.\n",
    "\n",
    "Routers allow conditional control flow inside the workflow.\n",
    "\n",
    "MessageState tracks conversation memory between user, LLM, and tool outputs.\n",
    "\n",
    "Multiple tools can be chained flexibly based on LLM reasoning.\n",
    "\n",
    "7. Conclusion\n",
    "External APIs extend an agent's knowledge and capability far beyond static LLM training.\n",
    "\n",
    "Combining API tools, LLM reasoning, and structured workflows creates powerful, responsive systems.\n",
    "\n",
    "LangGraph provides a clean, modular architecture to manage this complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318b1948-e43f-46e9-9271-612b9cdeb595",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65b120e3-a5d4-4bfc-80b1-a5118140727b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2263480a-07dd-4122-89b2-901f83597038",
   "metadata": {},
   "source": [
    "## Next demo - persisting memory with a database in LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7002d86b-7d83-49e4-a72a-b62800132371",
   "metadata": {},
   "source": [
    "Overview  \n",
    "This demo explains how to persist memory across sessions by saving conversation history into a SQLite database instead of keeping it only in RAM. This makes it possible to resume conversations later and builds the foundation for session-based systems.\n",
    "  \n",
    "Key Steps Covered  \n",
    "1. Helper Function for Running Graphs  \n",
    "A run_graph helper function is created to simplify invoking the graph repeatedly:\n",
    "\n",
    "Takes a query, the graph object, and a thread_id.\n",
    "\n",
    "def run_graph(query, graph, thread_id):\n",
    "\n",
    "  ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9af9a31-34d5-4963-a961-ec25d5ab6b69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import json\n",
    "from langchain_core.messages import (\n",
    "    SystemMessage,\n",
    "    AIMessage,\n",
    "    HumanMessage, \n",
    "    ToolMessage,\n",
    ")\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "from langgraph.graph.message import MessagesState\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.checkpoint.sqlite import SqliteSaver\n",
    "from IPython.display import Image, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c14691c-1775-4022-b9dc-bcdcb8cc1e43",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    model=\"gpt-4o-mini\",\n",
    "    temperature=0.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78c9c304-df6c-489e-80c1-a948b9f9bdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_graph(query:str, graph:StateGraph, thread_id:int):\n",
    "    output = graph.invoke(\n",
    "        config={\"configurable\":{\"thread_id\": thread_id}},\n",
    "        input={\"messages\":[HumanMessage(query)]}\n",
    "    )\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36456136-36b5-419a-9e3d-b0b052cd913a",
   "metadata": {},
   "source": [
    "2. In-Memory Workflow Setup  \n",
    "a. Workflow Definition  \n",
    "A simple workflow with a single chatbot node.\n",
    "  \n",
    "State: Based on MessageState.\n",
    "  \n",
    "\n",
    "workflow = StateGraph(MessageState)\n",
    "\n",
    "workflow.add_node(\"chatbot\", chatbot_node)\n",
    "\n",
    "workflow.add_edge(\"start\", \"chatbot\")\n",
    "\n",
    "workflow.add_edge(\"chatbot\", \"end\")  \n",
    "b. MemorySaver Checkpointer  \n",
    "A MemorySaver is used to checkpoint states in RAM only.\n",
    "\n",
    "from langgraph.checkpoints import MemorySaver\n",
    "\n",
    "memory = MemorySaver()\n",
    "\n",
    "workflow = StateGraph(MessageState, checkpointer=memory)  \n",
    "c. Execution  \n",
    "Queries like \"What is memory?\" are sent to the chatbot.\n",
    "\n",
    "Metadata about each step (node traversed, messages) is collected internally in memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de955527-5d2f-4da2-9928-20a2596227d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot(state: MessagesState):\n",
    "    ai_message = llm.invoke(state[\"messages\"])\n",
    "    return {\"messages\": ai_message}\n",
    "\n",
    "\n",
    "workflow = StateGraph(MessagesState)\n",
    "\n",
    "workflow.add_node(chatbot)\n",
    "workflow.add_edge(START, \"chatbot\")\n",
    "workflow.add_edge(\"chatbot\", END)\n",
    "\n",
    "checkpointer = MemorySaver()\n",
    "in_memory_graph = workflow.compile(checkpointer=checkpointer)\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        in_memory_graph.get_graph().draw_mermaid_png()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e5fc8c4-ae02-4029-8bdf-51263f1d2721",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_graph(\n",
    "    query=\"Hi\",\n",
    "    graph=in_memory_graph, \n",
    "    thread_id=\"1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4c38d3-3507-446a-b3b0-b3aabce1f46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(\n",
    "    in_memory_graph.get_state(\n",
    "        config={\"configurable\":{\"thread_id\": \"1\"}}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9746428-d763-43e0-943e-1cd089328702",
   "metadata": {},
   "source": [
    "3. SQLite-Persisted Workflow Setup  \n",
    "a. SqliteSaver Checkpointer  \n",
    "A SqliteSaver is used to persist workflow state to a SQLite database file (memory.db).\n",
    "\n",
    "from langgraph.checkpoints import SqliteSaver\n",
    "\n",
    "memory = SqliteSaver(db_path=\"memory.db\")\n",
    "\n",
    "workflow = StateGraph(MessageState, checkpointer=memory)\n",
    "The database file can be accessed and queried independently.  \n",
    "b. Execution  \n",
    "The same queries are sent, but this time, metadata and snapshots are saved into the SQLite database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc3ad81e-3cb9-468a-9eb0-0918c97c110f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For production, use something like Postgres\n",
    "db_path = \"memory.db\"\n",
    "conn = sqlite3.connect(db_path, check_same_thread=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8e38039-0e18-4c26-b1e9-e0f5083936f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory = SqliteSaver(conn)\n",
    "external_memory_graph = workflow.compile(checkpointer=memory)\n",
    "\n",
    "display(\n",
    "    Image(\n",
    "        external_memory_graph.get_graph().draw_mermaid_png()\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdcad8d-6b44-46c9-bb87-d55a74ad8d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_graph(\n",
    "    query=\"What's a memory?\",\n",
    "    graph=external_memory_graph, \n",
    "    thread_id=\"2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf198adb-532d-4055-a33e-7d77c7157d58",
   "metadata": {},
   "outputs": [],
   "source": [
    "list(\n",
    "    external_memory_graph.get_state(\n",
    "        config={\"configurable\":{\"thread_id\": \"2\"}}\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833d5ecd-a727-43d9-86cf-122d87231a9f",
   "metadata": {},
   "source": [
    "4. Inspecting the SQLite Database  \n",
    "a. Schema Inspection  \n",
    "A cursor is created to query the database.\n",
    "\n",
    "Two tables are found:\n",
    "\n",
    "checkpoints\n",
    "\n",
    "writes\n",
    "\n",
    "\n",
    "SELECT name FROM sqlite_master WHERE type='table'  \n",
    "b. Metadata Retrieval  \n",
    "Metadata columns contain serialized snapshots of:\n",
    "\n",
    "Node transitions\n",
    "\n",
    "Message exchanges (e.g., HumanMessage, AIMessage)\n",
    "\n",
    "Model configurations\n",
    "\n",
    "\n",
    "SELECT metadata FROM checkpoints  \n",
    "Example metadata entries:  \n",
    "\n",
    "Step -1: HumanMessage (\"What is memory?\")\n",
    "  \n",
    "Step 0: System setup\n",
    "  \n",
    "Step 1: AIMessage (\"Memory can refer to several concepts...\")\n",
    "  \n",
    "c. Advantages  \n",
    "Full history of each thread is preserved.\n",
    "\n",
    "Metadata includes model names, message types, and conversation content.\n",
    "\n",
    "Conversations can be resumed at any point by using the same thread_id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c84629e6-ad39-4dec-b257-664359ad2f1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor = conn.cursor()\n",
    "cursor.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tables = [table_name[0] for table_name in cursor.fetchall()]\n",
    "tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec700488-2cef-4b0a-be2b-7e6ead3044bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_map = []\n",
    "results = []\n",
    "\n",
    "for table in tables:\n",
    "    cursor.execute(f\"select * from {table}\")\n",
    "    results.append(cursor.fetchall())\n",
    "    columns_map.append({table:[desc[0] for desc in cursor.description]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afc6cf45-f540-4664-a69a-8b172902b560",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870650e5-41b8-4d03-8431-bf49c0079c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "cursor.execute(f\"select metadata from checkpoints\")\n",
    "metadata = cursor.fetchall()\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "326e1cfc-c577-496c-bad5-d6b30c14b7f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "steps = [json.loads(m[0]) for m in metadata]\n",
    "steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b854ee-9f6d-42e2-9ced-d5547ebcdf73",
   "metadata": {},
   "outputs": [],
   "source": [
    "5. Key Concepts Highlighted  \n",
    "MemorySaver is temporary; disappears when the session ends.\n",
    "\n",
    "SqliteSaver creates persistent, resumable sessions.\n",
    "\n",
    "Thread IDs differentiate multiple parallel conversations.\n",
    "\n",
    "Session management becomes trivial with database persistence:\n",
    "\n",
    "Can resume, search, or audit conversations.  \n",
    "6. Conclusion  \n",
    "Persisting memory with a database turns ephemeral conversations into durable sessions.\n",
    "\n",
    "LangGraph's checkpoint system allows flexible storage backends.\n",
    "\n",
    "This pattern is crucial for production-grade chatbot and agent applications that require history continuity across sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab35e81-2d72-41e8-9790-db22a2b0be05",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "23e30d6b-b719-462b-b210-bfcec291c6bf",
   "metadata": {},
   "source": [
    "## RAG Pipelines: Enhancing AI Agents with Retrieval and Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a651fbd5-b482-43b3-8f2d-14e7e2c69e94",
   "metadata": {},
   "source": [
    "Retrieval-Augmented Generation (RAG) enhances AI agents by retrieving relevant data from external sources and generating informed responses based on that data. This technique improves accuracy, ensures up-to-date information, and provides contextually relevant answers that go beyond an LLM’s training data.\n",
    "\n",
    "How a RAG Pipeline Works\n",
    "Retrieval\n",
    "The user submits a query.\n",
    "The query is converted into a vector representation using an embedding model.\n",
    "A vector database searches for similar stored content based on semantic similarity.\n",
    "Augmentation\n",
    "The retrieved information is added to the model’s context window.\n",
    "This enriches the input so the model has both the query and relevant background knowledge.\n",
    "Generation\n",
    "The LLM processes the augmented input and generates a response.\n",
    "The final output combines the model’s internal knowledge with retrieved external information.\n",
    "Use Case: E-Commerce Customer Support\n",
    "A user asks: “What is the return policy for electronics?”\n",
    "\n",
    "Without RAG – The agent gives a generic response based on its training data, which may be outdated or inaccurate.\n",
    "\n",
    "With RAG – The agent retrieves the actual return policy document, finds the relevant section, and generates a response based on company guidelines.\n",
    "\n",
    "Preparing Data for RAG Pipelines\n",
    "Before retrieval and generation can occur, documents must be collected, processed, and stored efficiently.\n",
    "\n",
    "Data Collection\n",
    "Sources include PDFs, websites, internal databases, and FAQs.\n",
    "Preprocessing\n",
    "Cleaning: Remove unnecessary text like HTML tags or special characters.\n",
    "Chunking: Break large documents into smaller sections (e.g., paragraphs or sentences).\n",
    "Embedding Generation: Convert text chunks into vector representations using models like OpenAI embeddings or bge-m3.\n",
    "Storage\n",
    "Store embeddings in a vector database (e.g., ChromaDB).\n",
    "Include metadata (e.g., source, date) to enable efficient filtering.\n",
    "RAG vs. Fine-Tuning\n",
    "Both RAG and fine-tuning enhance an agent’s performance but in different ways:\n",
    "\n",
    "Aspect\tRAG\tFine-Tuning\n",
    "How it works\tRetrieves external data at runtime\tAdjusts model weights using new data\n",
    "Best for\tDynamic, frequently updated data\tDomain-specific, long-term improvements\n",
    "Data needs\tLarge document corpus for retrieval\tSmall, high-quality training dataset\n",
    "Cost\tRequires vector storage, minimal compute\tRequires computational resources\n",
    "Risk\tRetrieval quality impacts accuracy\tCatastrophic forgetting is possible\n",
    "Choosing Between RAG and Fine-Tuning\n",
    "The best approach is combining both:\n",
    "\n",
    "Start with an LLM and strategic prompting – Quickly test feasibility.\n",
    "\n",
    "Integrate RAG – Improve accuracy with external data retrieval.\n",
    "\n",
    "Fine-tune a smaller model – Optimize performance once stable, reducing cost and latency.\n",
    "\n",
    "A fine-tuned customer support agent using RAG for live knowledge retrieval creates a personalized, real-time experience that is accurate and cost-efficient.\n",
    "\n",
    "Both techniques are powerful in agent design, and the right balance depends on the use case, cost, and update frequency of the required knowledge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b29f49d-4a43-46d0-a1d2-33fb5137fd17",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d657281-5896-4ff9-b96f-536a810d9429",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
